{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aaf4c3e",
   "metadata": {},
   "source": [
    "# Architectural Diagram with LangGraph\n",
    "\n",
    "This notebook sets up a conversation flow using LangGraph with multiple specialized agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict, Optional, List, Literal\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import json\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "   \"\"\"Graph state for the LLM.\"\"\"\n",
    "   messages: List[BaseMessage]  # Conversation history\n",
    "   next_step: str  # Next node to route to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd17750",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Load API keys and other configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad806775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "TUBE_API_KEY = os.getenv(\"TUBE_API_KEY\")\n",
    "SOURCE_COUNTRY_CODE = \"cl\"  # Default country code for news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398e1f8",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "Define specialized agents for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c79e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7064/3766535448.py:14: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  weather_llm = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "weather_system_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"\"\"You are a helpful weather assistant. When users ask about the weather,\n",
    "         get information for the specified city or location. Provide accurate and concise\n",
    "         responses about weather conditions. If coordinates are needed, you can work with\n",
    "         specific latitude and longitude values for cities.\"\"\"\n",
    "      ),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "weather_llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    "    callbacks=[],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "weather = weather_system_prompt | weather_llm.with_config(tags=[\"weather\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_system_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"\"\"You are a helpful financial assistant that provides accurate financial information. \n",
    "         Respond to queries about economic indicators, exchange rates, and financial markets.\n",
    "         Focus on providing current values, trends, and relevant context for financial data.\"\"\"\n",
    "      ),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "finance_llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    streaming=True,\n",
    "    callbacks=[],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "financial = financial_system_prompt | finance_llm.with_config(tags=[\"financial\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed047956",
   "metadata": {},
   "outputs": [],
   "source": [
    "notice_system_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"\"\"You are a helpful news assistant that provides current news and information. \n",
    "         When users ask about news, provide relevant, accurate, and recent news stories.\n",
    "         Focus on the most important details while being concise.\"\"\"\n",
    "      ),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "notice_llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    streaming=True,\n",
    "    callbacks=[],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "notice = notice_system_prompt | notice_llm.with_config(tags=[\"notice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9aab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_system_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"\"\"You are a helpful general assistant who can answer a wide variety of questions.\n",
    "         For questions about weather, financial information, or news, you'll indicate that\n",
    "         specialized assistants can provide better information.\"\"\"\n",
    "      ),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "general_llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "general = general_system_prompt | general_llm.with_config(tags=[\"general\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11efefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_system_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "      (\n",
    "         \"system\",\n",
    "         \"\"\"You are a supervisor that routes user queries to the appropriate specialized assistant.\n",
    "         \n",
    "         - 'weather': For questions about weather, temperature, climate conditions in any location\n",
    "         - 'financial': For questions about financial indicators, dollar value, UF, economic data\n",
    "         - 'notice': For requests about news, current events, or recent happenings\n",
    "         - 'general': For greetings, general knowledge questions, or anything that doesn't fit the above\n",
    "         \n",
    "         Based on the user's message, output ONLY ONE of these exact values: 'weather', 'financial', 'notice', or 'general'.\n",
    "         \"\"\"\n",
    "      ),\n",
    "      MessagesPlaceholder(variable_name=\"messages\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "supervisor_llm = ChatOllama(\n",
    "   model=\"llama3\",\n",
    "   temperature=0,\n",
    "   verbose=True,\n",
    "   base_url=\"http://localhost:11434\",\n",
    ")\n",
    "\n",
    "supervisor = supervisor_system_prompt | supervisor_llm.with_config(tags=[\"supervisor\"])# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6da70",
   "metadata": {},
   "source": [
    "## Tool Functions\n",
    "\n",
    "Define the tool functions for retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(input_str: str) -> dict:\n",
    "    \"\"\"\n",
    "    Search for the current weather in a given city.\n",
    "    \n",
    "    Args:\n",
    "        input_str (str): A string containing the city name and optional coordinates.\n",
    "            Example: '{\"city\": \"Madrid\"}' or '{\"city\": \"Madrid\", \"lat\": 40.4168, \"lon\": -3.7038}'\n",
    "            \n",
    "    Returns:\n",
    "        dict: The weather data for the given city.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the input\n",
    "        params = {}\n",
    "        if isinstance(input_str, dict):\n",
    "            params = input_str\n",
    "        elif isinstance(input_str, str):\n",
    "            # Clean up the input string - remove comments\n",
    "            lines = []\n",
    "            for line in input_str.split('\\n'):\n",
    "                # Remove anything after # (comments)\n",
    "                if '#' in line:\n",
    "                    line = line.split('#')[0]\n",
    "                lines.append(line)\n",
    "            clean_input = '\\n'.join(lines)\n",
    "            \n",
    "            try:\n",
    "                params = json.loads(clean_input)\n",
    "            except json.JSONDecodeError:\n",
    "                # Fall back to key=value parsing if not valid JSON\n",
    "                parts = input_str.split(',')\n",
    "                for part in parts:\n",
    "                    if '=' in part:\n",
    "                        key, value = part.split('=', 1)\n",
    "                        key = key.strip()\n",
    "                        value = value.strip().strip('\\'\"')\n",
    "                        \n",
    "                        # Convert numeric values\n",
    "                        try:\n",
    "                            if '.' in value and any(c.isdigit() for c in value):\n",
    "                                params[key] = float(value)\n",
    "                            elif value.isdigit():\n",
    "                                params[key] = int(value)\n",
    "                            else:\n",
    "                                params[key] = value\n",
    "                        except:\n",
    "                            params[key] = value\n",
    "        \n",
    "        # Get parameters with defaults\n",
    "        city = params.get('city', '')\n",
    "        lat = params.get('lat')\n",
    "        lon = params.get('lon')\n",
    "        units = params.get('units', 'metric')\n",
    "        lang = params.get('lang', 'es')\n",
    "        \n",
    "        # Validate parameters\n",
    "        if not city and (lat is None or lon is None):\n",
    "            return {\"error\": \"Missing required parameters: city or both lat and lon must be provided\"}\n",
    "        \n",
    "        # Prepare API request\n",
    "        url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "        api_params = {\n",
    "            \"appid\": WEATHER_API_KEY,\n",
    "            \"units\": units,\n",
    "            \"lang\": lang,\n",
    "        }\n",
    "        \n",
    "        # Set coordinates or city\n",
    "        if lat is not None and lon is not None:\n",
    "            api_params[\"lat\"] = float(lat)\n",
    "            api_params[\"lon\"] = float(lon)\n",
    "            print(f\"Using coordinates: Lat={lat}, Lon={lon}\")\n",
    "        else:\n",
    "            api_params[\"q\"] = city\n",
    "            print(f\"Using city name: {city}\")\n",
    "        \n",
    "        # Make the request\n",
    "        response = requests.get(url, params=api_params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        return {\"error\": f\"Invalid JSON format: {e}\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "        return {\"error\": f\"API request failed: {e}\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"error\": f\"Error processing request: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicator(indicator: str) -> dict:\n",
    "    \"\"\"Get financial information from Mindicador API.\n",
    "    \n",
    "    Args:\n",
    "        indicator (str): The indicator to fetch (e.g., \"dolar\", \"uf\", \"euro\")\n",
    "        \n",
    "    Returns:\n",
    "        dict: The data for the indicator\n",
    "    \"\"\"\n",
    "    url = f\"https://mindicador.cl/api/{indicator}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get(\"error\") is None:\n",
    "            return data\n",
    "        else:\n",
    "            return {\"error\": f\"API error: {data.get('mensaje', 'Unknown error')}\"}\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "        return {\"error\": f\"API request failed: {e}\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"error\": f\"Error processing request: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notices():\n",
    "    \"\"\"Get recent news from the API.\n",
    "    \n",
    "    Returns:\n",
    "        dict: News data with headlines and summaries\n",
    "    \"\"\"\n",
    "    url = f\"https://api.apitube.io/v1/news/everything?api_key={TUBE_API_KEY}&source.country.code={SOURCE_COUNTRY_CODE}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if \"error\" not in data:\n",
    "            # Extract only the essential information\n",
    "            simplified_data = {\n",
    "                \"articles\": [{\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"description\": article.get(\"description\"),\n",
    "                    \"url\": article.get(\"url\"),\n",
    "                    \"source\": article.get(\"source\", {}).get(\"name\")\n",
    "                } for article in data.get(\"articles\", [])][:5]  # Limit to 5 articles\n",
    "            }\n",
    "            return simplified_data\n",
    "        else:\n",
    "            return {\"error\": \"Error fetching news data\"}\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request error: {e}\")\n",
    "        return {\"error\": f\"API request failed: {e}\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return {\"error\": f\"Error processing request: {e}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9ebe8",
   "metadata": {},
   "source": [
    "## Node Functions\n",
    "\n",
    "Define node functions for the LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_router(state) -> Literal[\"weather\", \"financial\", \"notice\", \"general\"]:\n",
    "    \"\"\"Route the conversation to the appropriate node based on supervisor's decision.\"\"\"\n",
    "    # Extract the supervisor's decision from the state\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the last message which should be from the supervisor\n",
    "    last_message = messages[-1]\n",
    "    content = last_message.content.lower().strip()\n",
    "    \n",
    "    # Map content to valid next nodes\n",
    "    valid_nodes = [\"weather\", \"financial\", \"notice\", \"general\"]\n",
    "    \n",
    "    # Check if content exactly matches one of our valid nodes\n",
    "    for node in valid_nodes:\n",
    "        if node in content:\n",
    "            return node\n",
    "    \n",
    "    # Default to general if no match is found\n",
    "    return \"general\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f794bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def supervisor_node(state):\n",
    "    \"\"\"Supervisor node that decides which agent should handle the request.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the user's message\n",
    "    user_message = next(\n",
    "        (msg for msg in reversed(messages) if isinstance(msg, HumanMessage)), \n",
    "        None\n",
    "    )\n",
    "    \n",
    "    if not user_message:\n",
    "        # No user message found, default to general\n",
    "        return {\"messages\": messages + [SystemMessage(content=\"general\")]}\n",
    "    \n",
    "    # Create a message list for the supervisor with just the user's question\n",
    "    supervisor_messages = [HumanMessage(content=user_message.content)]\n",
    "    \n",
    "    # Ask the supervisor to decide which agent should handle this\n",
    "    response = await supervisor.invoke(supervisor_messages)\n",
    "    \n",
    "    # Return the decision in the messages\n",
    "    return {\"messages\": messages + [SystemMessage(content=response.content)]}\n",
    "\n",
    "async def weather_node(state):\n",
    "    \"\"\"Weather agent node that handles weather-related queries.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = await weather.invoke(messages)\n",
    "    return {\"messages\": messages + [response]}\n",
    "\n",
    "async def financial_node(state):\n",
    "    \"\"\"Financial agent node that handles financial queries.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = await financial.invoke(messages)\n",
    "    return {\"messages\": messages + [response]}\n",
    "\n",
    "async def notice_node(state):\n",
    "    \"\"\"News agent node that handles news-related queries.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = await notice.invoke(messages)\n",
    "    return {\"messages\": messages + [response]}\n",
    "    \n",
    "async def general_node(state):\n",
    "    \"\"\"General agent node that handles all other queries.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = await general.invoke(messages)\n",
    "    return {\"messages\": messages + [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3950c",
   "metadata": {},
   "source": [
    "## Graph Definition\n",
    "\n",
    "Define the graph structure for conversation flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0064b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7ad2a0153bf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define the graph\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"weather\", weather_node)\n",
    "graph.add_node(\"financial\", financial_node)\n",
    "graph.add_node(\"notice\", notice_node)\n",
    "graph.add_node(\"general\", general_node)\n",
    "\n",
    "# Add edges\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "graph.add_edge(\"supervisor\", supervisor_router)\n",
    "\n",
    "# Each agent node connects to the end\n",
    "graph.add_edge(\"weather\", END)\n",
    "graph.add_edge(\"financial\", END)\n",
    "graph.add_edge(\"notice\", END)\n",
    "graph.add_edge(\"general\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c13a9",
   "metadata": {},
   "source": [
    "## Graph Visualization\n",
    "\n",
    "Visualize the conversation flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al generar imagen con draw_mermaid_png: 'StateGraph' object has no attribute 'get_graph'\n",
      "Error con la alternativa de visualización: 'StateGraph' object has no attribute 'get_graph'\n",
      "\n",
      "Estructura del grafo:\n",
      "Nodos: ['weather', 'financial', 'notice']\n",
      "Aristas: [('__start__', 'weather'), ('weather', 'financial'), ('notice', '__end__'), ('financial', 'notice')]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Try to visualize with native langgraph methods\n",
    "    graph_img = graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_img))\n",
    "except Exception as e:\n",
    "    print(f\"Error generating image with draw_mermaid_png: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Alternative: Export to DOT and use Graphviz directly\n",
    "        dot_graph = graph.get_graph().to_dot()\n",
    "        \n",
    "        # Save the dot in a temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix='.dot') as tmp:\n",
    "            tmp.write(dot_graph.encode('utf-8'))\n",
    "            tmp.flush()\n",
    "            \n",
    "            # Generate PNG with graphviz from command line\n",
    "            png_file = f\"{tmp.name}.png\"\n",
    "            os.system(f\"dot -Tpng {tmp.name} -o {png_file}\")\n",
    "            \n",
    "            if os.path.exists(png_file):\n",
    "                display(Image(filename=png_file))\n",
    "                os.remove(png_file)  # Cleanup\n",
    "            else:\n",
    "                print(\"Could not generate image with Graphviz\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error with alternative visualization: {e2}\")\n",
    "        \n",
    "    # Show basic graph info as fallback\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(f\"Nodes: {[node for node in graph.nodes]}\")\n",
    "    print(f\"Edges: {[(src, dst) for src, dst in graph.edges]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ee728",
   "metadata": {},
   "source": [
    "## Sample Usage\n",
    "\n",
    "Test the conversation flow with sample inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instala langchain-visualizer: pip install langchain-visualizer\n",
      "{'edges': [('__start__', 'weather'),\n",
      "           ('weather', 'financial'),\n",
      "           ('notice', '__end__'),\n",
      "           ('financial', 'notice')],\n",
      " 'nodes': ['weather', 'financial', 'notice']}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Test function to interact with the graph\n",
    "async def test_query(user_input: str):\n",
    "    \"\"\"Test a query through the conversation graph.\"\"\"\n",
    "    messages = [HumanMessage(content=user_input)]\n",
    "    result = await app.ainvoke({\"messages\": messages})\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            print(f\"\\033[33m[System] {msg.content}\\033[0m\")\n",
    "        elif not isinstance(msg, HumanMessage):\n",
    "            print(f\"\\033[32m[Assistant] {msg.content}\\033[0m\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various queries\n",
    "test_queries = [\n",
    "    \"¿Qué tiempo hace hoy en Madrid?\",\n",
    "    \"¿Cuál es el valor del dólar hoy?\",\n",
    "    \"¿Qué noticias hay sobre política?\",\n",
    "    \"Hola, ¿cómo estás?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n\\033[1;34m[User Query] {query}\\033[0m\\n\")\n",
    "    await test_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a124b",
   "metadata": {},
   "source": [
    "## API Integration\n",
    "\n",
    "Define functions to integrate with an API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09949cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, WebSocket, Request\n",
    "import asyncio\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# This code would be used in a separate API file\n",
    "async def process_message(message_content):\n",
    "    \"\"\"Process a message through the graph and return the response.\"\"\"\n",
    "    messages = [HumanMessage(content=message_content)]\n",
    "    result = await app.ainvoke({\"messages\": messages})\n",
    "    \n",
    "    # Extract the assistant's response\n",
    "    for msg in reversed(result[\"messages\"]):\n",
    "        if not isinstance(msg, (HumanMessage, SystemMessage)):\n",
    "            return msg.content\n",
    "    \n",
    "    return \"Lo siento, no pude procesar tu solicitud.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
